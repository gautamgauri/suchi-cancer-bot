#!/usr/bin/env node

import { Command } from "commander";
import { Evaluator } from "./runner/evaluator";
import { ReportGenerator } from "./runner/report-generator";
import { ApiClient } from "./runner/api-client";
import { loadConfig } from "./config/loader";
import * as path from "path";
import * as fs from "fs/promises";

const program = new Command();

program
  .name("eval")
  .description("Suchi Bot Evaluation Framework")
  .version("1.0.0");

program
  .command("run")
  .description("Run evaluation tests")
  .option("-c, --case <id>", "Run specific test case by ID")
  .option("-t, --tier <number>", "Run tests for specific tier", parseInt)
  .option("--cancer <type>", "Filter by cancer type")
  .option("--intent <type>", "Filter by intent type")
  .option("--cases <path>", "Path to test cases YAML file", "cases/tier1/common_cancers_20_mode_matrix.yaml")
  .option("--rubrics <path>", "Path to rubrics JSON file", "rubrics/rubrics.v1.json")
  .option("--config <path>", "Path to config file")
  .option("--output <path>", "Output path for report JSON", "report.json")
  .option("--summary", "Print summary to console")
  .option("--batch-size <number>", "Run tests in batches of N cases", parseInt)
  .action(async (options) => {
    try {
      console.log("Loading configuration...");
      const config = await loadConfig(options.config);

      console.log("Loading test cases...");
      const casesPath = path.isAbsolute(options.cases) 
        ? options.cases 
        : path.resolve(process.cwd(), options.cases);
      const testCases = await Evaluator.loadTestCases(casesPath);

      console.log("Loading rubrics...");
      const rubricsPath = path.isAbsolute(options.rubrics)
        ? options.rubrics
        : path.resolve(process.cwd(), options.rubrics);
      const rubricPack = await Evaluator.loadRubrics(rubricsPath);

      // Filter test cases
      const filters: any = {};
      if (options.case) filters.caseId = options.case;
      if (options.tier) filters.tier = options.tier;
      if (options.cancer) filters.cancer = options.cancer;
      if (options.intent) filters.intent = options.intent;

      // ‚úÖ PREFLIGHT: Validate filters before running any tests
      const validation = Evaluator.validateFilters(testCases, filters);
      
      // Print discovered values
      console.log(`\nüìã Test Suite Summary:`);
      console.log(`  Total cases in suite: ${validation.totalCases}`);
      console.log(`  Selected cases: ${validation.selectedCases}`);
      if (validation.availableCancerTypes.length > 0) {
        console.log(`  Available cancer types: ${validation.availableCancerTypes.join(', ')}`);
      }
      if (validation.availableIntents.length > 0) {
        console.log(`  Available intents: ${validation.availableIntents.join(', ')}`);
      }
      
      // Print filter values (canonicalized)
      if (filters.cancer) {
        const { canonicalCancerType } = require('./utils/canonicalize');
        console.log(`  Requested cancer: "${filters.cancer}" ‚Üí canonicalized to "${canonicalCancerType(filters.cancer)}"`);
      }
      if (filters.intent) {
        const { canonicalIntent } = require('./utils/canonicalize');
        console.log(`  Requested intent: "${filters.intent}" ‚Üí canonicalized to "${canonicalIntent(filters.intent)}"`);
      }
      
      // ‚úÖ FAIL-FAST: Abort if filter matches 0 cases
      if (validation.errors.length > 0) {
        console.error(`\n‚ùå PREFLIGHT VALIDATION FAILED:\n`);
        validation.errors.forEach(err => console.error(`  ${err}`));
        process.exit(1);
      }
      
      // Warn if selection seems unexpected
      if (validation.warnings.length > 0) {
        console.warn(`\n‚ö†Ô∏è  Warnings:`);
        validation.warnings.forEach(warn => console.warn(`  ${warn}`));
        console.warn(`  Continuing anyway...\n`);
      }

      const filteredCases = Evaluator.filterTestCases(testCases, filters);

      // ‚úÖ NEW: Warm-up API to prevent cold start on first test case
      console.log("\nüî• Warming up API...");
      try {
        const warmupClient = new ApiClient(config.apiBaseUrl, 30000, config.authBearer); // 30s timeout
        const warmupSession = await warmupClient.createSession("web");
        await warmupClient.sendMessage(
          warmupSession,
          "What is cancer?", // Simple query
          "web"
        );
        console.log("‚úÖ API warmed up\n");
      } catch (error: any) {
        console.warn("‚ö†Ô∏è Warm-up failed (continuing anyway):", error.message);
      }

      // Create evaluator and report generator
      const evaluator = new Evaluator(config, rubricPack);
      const reportGenerator = new ReportGenerator();
      const outputPath = path.resolve(process.cwd(), options.output);

      // Apply batching if batch-size is specified
      let results;
      if (options.batchSize && options.batchSize > 0) {
        const batches: typeof filteredCases[] = [];
        for (let i = 0; i < filteredCases.length; i += options.batchSize) {
          batches.push(filteredCases.slice(i, i + options.batchSize));
        }
        
        console.log(`Running ${filteredCases.length} test case(s) in ${batches.length} batch(es) of ${options.batchSize}...`);
        
        // Process batches sequentially
        const allResults = [];
        for (let i = 0; i < batches.length; i++) {
          const startCase = i * options.batchSize + 1;
          const endCase = Math.min((i + 1) * options.batchSize, filteredCases.length);
          console.log(`\nBatch ${i + 1}/${batches.length}: Cases ${startCase}-${endCase}`);
          const batchResults = await evaluator.evaluateTestCases(batches[i]);
          allResults.push(...batchResults);
          
          // ‚úÖ NEW: Write incremental report after each batch
          const partialReport = reportGenerator.generateReport(allResults, config);
          await reportGenerator.exportToFile(partialReport, outputPath);
          console.log(`  üíæ Progress saved: ${allResults.length}/${filteredCases.length} cases`);
        }
        
        results = allResults;
      } else {
        console.log(`Running ${filteredCases.length} test case(s)...`);
        
        // ‚úÖ NEW: Write after each case for non-batched runs
        const allResults = [];
        for (let i = 0; i < filteredCases.length; i++) {
          console.log(`\n[${i + 1}/${filteredCases.length}] Evaluating ${filteredCases[i].id}...`);
          const result = await evaluator.evaluateTestCase(filteredCases[i]);
          allResults.push(result);
          
          // Write incremental report after each case
          const partialReport = reportGenerator.generateReport(
            allResults,
            config,
            undefined,
            { loadedCount: testCases.length, selectedCount: filteredCases.length }
          );
          await reportGenerator.exportToFile(partialReport, outputPath);
          console.log(`  üíæ Progress saved: ${allResults.length}/${filteredCases.length} cases`);
        }
        
        results = allResults;
      }

      // ‚úÖ FAIL-FAST: Check if we executed 0 cases
      if (results.length === 0) {
        console.error(`\n‚ùå ERROR: No test cases were executed!`);
        console.error(`  Selected cases: ${filteredCases.length}`);
        console.error(`  This indicates a filter or execution problem.`);
        process.exit(1);
      }

      // Generate final report
      const report = reportGenerator.generateReport(
        results,
        config,
        undefined,
        { loadedCount: testCases.length, selectedCount: filteredCases.length }
      );

      // Include LLM cost summary if available
      const costSummary = evaluator.getLLMCostSummary();
      if (costSummary && (costSummary.totalCost > 0 || costSummary.fallbackUsedCount > 0)) {
        (report as any).llmCost = {
          totalCost: costSummary.totalCost,
          totalTokens: costSummary.totalTokens,
          callCount: costSummary.callCount,
          fallbackUsedCount: costSummary.fallbackUsedCount,
          formatted: `$${costSummary.totalCost.toFixed(4)} (${costSummary.totalTokens.toLocaleString()} tokens, ${costSummary.callCount} calls)`
        };
        console.log(`\nüí∞ LLM cost: ${(report as any).llmCost.formatted}`);
        if (costSummary.fallbackUsedCount > 0) {
          console.log(`  üîÑ Fallback used: ${costSummary.fallbackUsedCount} times (Gemini Flash)`);
        }
      }

      // ‚úÖ VALIDATION: Check if report is invalid (0 executed)
      if (report.suite?.status === 'INVALID') {
        console.error(`\n‚ùå ERROR: Report is INVALID - 0 cases executed!`);
        console.error(`  Suite loaded: ${report.suite.loadedCount}`);
        console.error(`  Suite selected: ${report.suite.selectedCount}`);
        console.error(`  Suite executed: ${report.suite.executedCount}`);
        process.exit(1);
      }

      // Save final report (ensures completeness marker)
      await reportGenerator.exportToFile(report, outputPath);
      console.log(`\n‚úÖ Final report saved to: ${outputPath}`);

      // Print summary if requested
      if (options.summary) {
        console.log("\n" + reportGenerator.generateSummaryText(report));
      } else {
        console.log(`\nSummary: ${report.summary.passed}/${report.summary.total} passed`);
        console.log(`Average Score: ${(report.summary.averageScore * 100).toFixed(1)}%`);
      }
    } catch (error: any) {
      console.error("Error:", error.message);
      process.exit(1);
    }
  });

program
  .command("report")
  .description("Generate report from existing results")
  .option("--input <path>", "Path to results JSON file", "report.json")
  .option("--output <path>", "Output path for formatted report")
  .option("--format <type>", "Report format: json, text", "text")
  .action(async (options) => {
    try {
      const inputPath = path.resolve(process.cwd(), options.input);
      const content = await fs.readFile(inputPath, "utf-8");
      const report = JSON.parse(content);

      const reportGenerator = new ReportGenerator();

      if (options.format === "text") {
        const summary = reportGenerator.generateSummaryText(report);
        if (options.output) {
          await fs.writeFile(options.output, summary, "utf-8");
          console.log(`Report saved to: ${options.output}`);
        } else {
          console.log(summary);
        }
      } else {
        if (options.output) {
          await fs.writeFile(options.output, JSON.stringify(report, null, 2), "utf-8");
          console.log(`Report saved to: ${options.output}`);
        } else {
          console.log(JSON.stringify(report, null, 2));
        }
      }
    } catch (error: any) {
      console.error("Error:", error.message);
      process.exit(1);
    }
  });

program.parse();

